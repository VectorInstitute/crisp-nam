<!DOCTYPE html>
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=1300">
  <style id="distill-article-specific-styles">
    <%= require("raw-loader!./style.css") %>
  </style>
  <style>
    /* Override default list styling to prevent double bullets */
    d-contents ul, d-contents li {
      list-style-type: none !important;
    }
    d-contents li::marker {
      display: none !important;
      content: '' !important;
    }
  </style>
  <script src="https://distill.pub/template.v2.js"></script>
  <!-- Bundle will be automatically injected here by webpack -->
</head>
<body>

<d-front-matter>
  <script type="text/json">{
  "title": "CRISP-NAM: Competing Risks Interpretable Survival
  Prediction with Neural Additive Models",
  "description": "Sample blog post for AI Engineering",
  "authors": [
    {
      "author": "Dhanesh Ramachandram",
      "affiliation": "Vector Institute",
      "affiliationURL": "https://vectorinstitute.ai"
    }, {
      "author": "Ananya Raval",
    }
  ],
  "katex": {
    "delimiters": [
      {"left": "$", "right": "$", "display": false},
      {"left": "$$", "right": "$$", "display": true}
    ]
  }
  }</script>
</d-front-matter>

<d-title>
  <h1>CRISP-NAM: Interpretable survival prediction</h1>
  <p>
    <b>C</b>ompeting <b>R</b>isks <b>I</b>nterpretable <b>S</b>urvival
    <b>P</b>rediction with <b>N</b>eural <b>A</b>dditive <b>M</b>odels - A model that enhances interpretability in survival analysis.
  </p>
</d-title>

<d-byline></d-byline>

<d-article>
  <d-contents>
    <nav class="toc figcaption">
      <h4>Contents</h4>
      <div class="toc-section"><a href="#overview">AI IN HEALTHCARE
    </a>
        <ul>
          <li><a href="#challenges">Challenges</a></li>
          <li><a href="#surv">Survival Analysis: A primer</a>
            <ul>
                <li><a href="#competing-risks">Competing risks: Multiple causes for the same outcome</a></li>
            </ul>
          </li>
          <li><a href="#existing-models">Existing Models</a></li>
          <li><a href="#limitations">Limitations of existing approaches</a></li>
        </ul>
      </div>
      <div class="toc-section"><a href="#crisp-nam">Our solution: CRISP-NAM</a>
        <ul>
          <li><a href="#inspiration">Inspiration of CRISP-NAM</a></li>
          <li><a href="#architecture">Architecture</a></li>
          <li><a href="#advantages">Advantages</a></li>
          <li><a href="#limitations">Limitations</a></li>
        </ul>
      </div>
      <div class="toc-section"><a href="#Evaluation"> Evaluation</a>
        <ul>
          <li><a href="#support2">Support 2 dataset</a></li>
          <li><a href="#results">Results</a></li>
        </ul>
      </div>
      <div class="toc-section"><a href="#interp">Interpretability</a></div>
      <div class="toc-section"><a href="#conclusion">Conclusion</a></div>
    </nav>
    <div class="toc-line"></div>
  </d-contents>

  <h2 id="overview">AI In healthcare</h2>

  <p>In the past decade, AI has made numerous advances in the field of healthcare. Sophisticated algorithms are available to analyze and interpret medical images such as X-rays and CT scans, accelerating disease diagnosis. AI’s ability to synthesize and understand large amounts of patient data (genetics, biomarkers, clinical history) has led to personalized treatment plans and individualized therapies. Drug discovery, disease risk prediction and assessment, and survival analysis are other areas where new AI models have been developed. These AI-driven systems promise greater efficiency and accuracy in the healthcare ecosystem. However, many challenges remain for their widespread deployment and adoption. <d-cite key="https://pmc.ncbi.nlm.nih.gov/articles/PMC11638409/"/></p>

  <h3 id="challenges">Challenges</h3>

  <p>Current generative AI models achieve a very high accuracy in classification and prediction. However, they suffer from multiple limitations.
    <ul>
        <li><strong>Interpretability</strong>: Deep learning models are black boxes, and it is challenging to determine how they make a particular prediction. In a high-stakes field such as healthcare, clinicians must understand the reasoning behind a model’s output. Misinterpretation can lead to incorrect treatment plans or adverse patient outcomes.</li>

        <li><strong>Data privacy</strong>: Many AI models are trained using vast amounts of patient data - EHR, images, etc. It contains personally identifiable information that needs to be protected. This can require regulatory practises in place before more widespread adoption.</li>

        <li><strong>Regulatory frameworks</strong>: Many policies have established explainability and interpretability constraints for high-risk AI systems. As an example, the Food and Drug Administration (FDA) guidance requires clear documentation of AI/ML medical device decision-making.</li>
    
    </ul>Our focus in this blog will be on developing <b>interpretable</b>techniques for survival analysis use cases. It is a robust framework for providing time-to-event predictions, especially in healthcare.
  </p>

  <h3 id="surv">Survival Analysis: Primer</h3>

  <p>Survival analysis is a collection of statistical procedures for data analysis where the outcome is time-to-event, meaning time until an event of interest occurs. For example, clinicians utilize patient data <i>(covariates)</i> to predict the timing of hospital readmissions for specific medical conditions. There can be multiple outcomes  (such as cardiovascular risk, death, etc.) associated with patient data, and multiple mutually exclusive events that can lead to any outcome. These outcomes are referred to as <i>competing risks</i>. Survival modelling learns functions to map a patient’s data <i>(covariates)</i> to the time of occurrence of a single outcome <i>(time-to-event)</i>.</p>

  <h3 id="competing-risks">Competing risks: Multiple causes for the same outcome</h3>
  <p>
    Consider a clinician managing patients with advanced liver disease. The goal is to predict outcomes, but patients
    face more than one possible endpoint. Some will pass away while waiting for treatment; others will receive a liver
    transplant. These events <em>compete</em> with each other: once a patient receives a transplant, they exit the waiting-list , and vice versa.
  </p>
  <p>
    This is the problem of <i><strong>competing risks</strong></i>, and it appears throughout the healthcare sector:
  </p>
  <ul>
    <li>Cancer patients may die from their malignancy or from other causes</li>
    <li>Heart disease patients face cardiovascular events or non-cardiac mortality</li>
    <li>Hospitalized patients may be discharged or die during their stay</li>
  </ul>
  <p>
    Traditional survival models that predict time-to-event were not designed to handle this complexity. While deep
    learning has introduced powerful approaches to survival analysis, most operate as black boxes, providing
    predictions without explanations.
  </p>
  <p>
    <strong>CRISP-NAM addresses this gap</strong> by handling competing risks
    while maintaining interpretability, and allowing practitioners to examine exactly how each feature influences each risk. Below is a figure illustrating how competing risks are modeled in survival analysis.
  </p>
  <figure>
    <img src="assets/ism_overview-cropped.svg" alt="Survival Model Overview" style="width: 100%; max-width: 1200px; margin: 0 auto 1rem auto; display: block;  border-radius: 4px;">
    <figcaption>Figure 1: Sketch of modeling competing risks in survival analysis.</figcaption>
  </figure>

  <h3 id="existing-models">Existing Models</h3>
  <p>Many statistical and machine learning techniques have been used to capture the interactions between covariates and time-to-event variables. The following are a few classes of models that exist in the literature:
    <ul>
    <li><strong>Traditional</strong>: Cox Proportional Hazards(CoxPH) is a popular model. It linearly maps covariates to time-to-event prediction. It assumes a multiplicative effect of covariates on the prediction and that their effect is constant over time.</li>
    <li><strong>Deep Learning</strong>: This class of models uses a feed-forward neural network for mapping covariates to the risk of the outcome. This captures non-linear and high-dimensional relationships between the two variables. DeepSurv, CoxNAM, and SurvNam are a few examples. </li>
    <li><strong>Models for competing risks</strong>: Such models follow a cause-specific hazard framework to model multiple risks. These models map covariates to each competing risk separately and learn the joint distribution of survival times and the risks directly. DeepHit and  Neural Fine Gray are a few examples. </li>
    </ul>
  </p>
  <h3 id="limitations">Limitations of existing approaches</h3>
  <p> There are multiple limitations to existing approaches:
    <ul>
    <li><strong>Insufficient parameters</strong>: Many traditional models(CoxPH) are linear. They fail to capture the non-linearity between the covariates and time-to-event variables. </li>
    <li><strong>Lack of interpretability</strong>: Deep learning survival models (DeepSurv) are black-box and suffer from a lack of interpretability.  This makes it difficult to understand how individual features contribute to predictions for different competing risks. </li>
    <li><strong>Require >1 model</strong>: Cause-specific modelling requires learning multiple models - one for each outcome. This can be computationally expensive.</li>
    </ul>
    </p>

  <h2 id="overview">Our solution: CRISP-NAM</h2>
  <p>To address these limitations, we developed a novel approach for modeling competing risks, CRISP-NAM -  <b>C</b>ompeting <b>R</b>isks <b>I</b>nterpretable <b>S</b>urvival <b>P</b>rediction with <b>N</b>eural <b>A</b>dditive <b>M</b>odels. It extends the NAM architecture approach to enable flexible, interpretable, and non-linear modeling.
  </p>
  <figure>
    <iframe src="./diagrams/venn.html" width="700" height="500" style="border: none;"></iframe>
    <figcaption style="margin-top: 20px; text-align: left; max-width: 800px; margin-left: auto; margin-right: auto;">
      </figcaption>
    </figure>
    <h3 id="inspiration">Inspiration of CRISP-NAM</h3>
    <p>
        CRISP-NAM is a derivative of Generalized Additive Model (GAM) family. GAMs have been a statistical mainstay for decades. Rather than assuming linear covariate-outcome relationships, they allow each covariate to have its own contribution via a separate <i>spline</i> function. Spline functions capture non-linear relationships such as thresholds, curves and saturation effects that linear models cannot represent. Since covariate has its own function, and they are added together, GAMs can provide insights into how each feature affects the outcome.
    </p>
    <p>
      <b>Neural Networks as Shape Functions:</b> NAMs replace traditional spline-based functions with small neural networks, one per feature. Each neural network takes a single feature and models its contribution to the outcome. Training NAMs is easier and offers multiple advantages such as automatic weight learning, standard regularization techniques, and GPU acceleration. Even though NAMs don't model covariate interactions, their ability to model single covariate's effect is what makes them interpretable.
      </p>
      <div id="nam-structure-diagram" style="width: 100%; height: 400px; margin: 20px 0;"></div>
    <h3 id="architecture">Architecture</h3>
    <p>The CRISP-NAM architecture consists of 4 components:
        <ul>
        <li><strong>FeatureNets</strong>: Each input feature is processed by its own dedicated neural network called <i>FeatureNet</i>. This sub-network is designed to learn the feature’s non-linear contribution to the overall outcome. Since it isolates the effects of each feature, it is more interpretable than existing approaches. </li>
        <li><strong>Risk-Specific Projections</strong>: Each covariate and competing risk pair is then linearly transformed by a dedicated projection layer to measure its contribution to the outcome. Normalization constraint is added to ensure that contribution scales are comparable across risks enabling fair comparisonof feature importance between different event types.</li>
        <li><strong>Additive Risk Aggregation</strong>: Individual risk contribution to the hazard function is computed as the sum of individual feature contributions, preserving the additive nature of the original NAM model.</li>
        <li><strong>Cause-specific Log Hazard Calculation</strong>: This calculates the absolute probability for each risk by capturing the underlying temporal pattern independent of the covariates. It calculates the final risk probability with patients experiencing it within a specified time-interval and a cause-specific baseline measure. </li>
        </ul>
    </p>
    <div id="crisp-nam-structure-diagram" style="width: 100%; height: 400px; margin: 20px 0;">
    </div>
    <h3 id="advantages">Advantages</h3>
    <ul>
        <li>It retains the interpretability and feature-wise transparency of NAMs, allowing for flexible and non-linear modelling in competing risk scenarios. This enables us to visualize each feature’s contribution via shape plots, enhancing interpretability.</li>
        <li>The calculation of absolute risks is done independently of patient covariates. This provides predictions for clinically relevant time horizons (1-year, 5-year) and facilitates better patient care.</li>
    </ul>
    <h3 id="limitations">Limitations</h3>
        <p>
          By design, the model excludes feature interactions. This is
          intentional, as interactions make interpretation exponentially more difficult. With <d-math>p</d-math>
          features, there are <d-math>O(p^2)</d-math> pairwise interactions, and visualization beyond pairwise terms
          becomes impractical. We accept some reduction in predictive power in exchange for guaranteed interpretability.
        </p>
    </h3>
    <h2 id="evaluation">Evaluation</h2>
    <p>
        The dataset was evaluated using a mix of both discriminative and calibration metrics. 
        <ol>
        <li><strong>Time-Dependent Area-Under-the-Curve (TD-AUC)</strong>: It is an extension of the standard ROC-AUC designed specifically for time-to-event (survival) data, where outcomes happen over time. It measures how well the model ranks patients for an event that happened at time <i>t</i> over those who didn’t experience the events were censored. </li>
        <li><strong>Time-Dependent Concordance Index (TD-CI)</strong>: Concordance Index (CI) measures the proportion of pairs for which the model correctly predicts the survival time, among all pairs for which this can be acurately determined. Time-depenent CI calculates this count within a common observation time interval. It is a good metric to assess model performance over time.</li>
        <li><strong>Brier score (BS)</strong>: This score evaluates the accuracy of a survival function at a given time <i>t</i>. It calculates the average of squared distances between the observed survival status and the predicted survival probability. This is a combined measure of caliberation and discrimination.</li>
    </p>
    <h3 id="support2">Support 2 dataset</h3>
    The SUPPORT2 dataset originates from the Study to Understand Prognoses
    and Preferences for Outcomes and Risks of Treatments (SUPPORT2), a comprehensive investigation conducted across five U.S. medical centers between 1989 and 1994. This dataset contains 9,105 records of critically ill hospitalized adults, each characterized by 42 variables containing the following classes:
    <ul>
        <li><strong>Demographics</strong>: age, death, sex, income </li>
        <li><strong>Physiological measurements</strong>: ph, glucose, urine</li>
        <li><strong>Disease severity indicators</strong>: diabetes, dementia</li>
    </ul>
    This dataset was chosen as it contains 2 competing risks: Death due to cancer and Death due to other reasons.

    <h3 id="results">Results</h3>
      <p>
        Below are the performance metrics comparing CRISP-NAM and the state-of-the-art DeepHIT model for the two competing risks: Death due to cancer (Risk 1) and death due to other causes (Risk 2).
      </p>
      <figure>
        <iframe src="./diagrams/results-table.html" width="100%" height="400" style="border: none;"></iframe>
      </figure>

      <p>
        CRISP-NAM shows better performance in Risk 1, and DeepHIT is better in Risk 2. Across more datasets, such as Framingham Heart Study and Primary Biliary Cholangitis (PBC), DeepHit generally achieves a higher performance, and CRISP-NAM demonstrates competitive discrimination with the added benefit of interpretability.

        The main point to note here is that CRISP-NAM achieves <b>comparable performance to DeepHIT while providing interpretability</b>, which is crucial for clinical adoption.
      </p>

  <h2 id="interp">Interpretability</h2>
  <p>
    <ol>
      <li><strong>Feature importance plots</strong>: These plots summarize a covariate’s contribution to the final output of the model. In CRISP-NAM, it is the mean of the covariates risk projection vector for a particular risk. Its value determines the positive and negative contributions to the risk.</li>
    <figure>
        <iframe src="./diagrams/feature_importance.html" width="100%" height="600" style="border: none;"></iframe>
    </figure>

    <li><strong>Shape plots</strong>:  Plotted for every covariate, it shows its individual contribution to the overall probability of the risk. Beneath each curve, rug plots illustrate the empirical distribution of feature values, highlighting regions where data is sparse. For CRISP-NAM, this plot is the risk projection vector of every covariate per risk. This enables ranking features by their impact on each competing risk, providing valuable insights into risk-specific predictor importance.</li>
    </ol>
    <p><b>TODO: Add shape plots</b></p>
  </p>
  <h2 id="conclusion">Conclusion</h2>
  <p>
    CRISP-NAM demonstrates that interpretability and competitive predictive performance are not mutually exclusive, even for complex problems like competing risks survival analysis. By extending Neural Additive Models to handle multiple event types, we provide clinicians and researchers with a tool that achieves strong discrimination while fully explaining its predictions.
  </p>
  <p>
    In high-stakes healthcare applications, understanding why a model makes its predictions is not a luxury but a requirement. CRISP-NAM makes that understanding achievable.
  </p>

  <p>The source code for reproducing all experiments and implementations described in this article is available in our <a href="https://github.com/VectorInstitute/crisp-nam" target="_blank">CRISP-NAM repository</a>.</p>

  <div class="citation">
    <h3>Citation</h3>
    <pre>@inproceedings{ramachandram2025crispnam,
    title={CRISP-NAM: Competing Risks Interpretable Survival Prediction with Neural Additive Models},
    author={Ramachandram, Dhanesh and Raval, Ananya},
    booktitle={EXPLIMED 2025 - Second Workshop on Explainable AI for the Medical Domain},
    year={2025}
    }</pre>
  </div>
</d-article>

<d-appendix>
  <h3 id="acknowledgements">Acknowledgments</h3>
    <p>
        We would like to thank the Vector Institute for supporting this research, and the open-source community for providing valuable datasets, tools and frameworks that made this work possible.
    </p>
  <d-bibliography src="references.bib"></d-bibliography>
  <p><b>TODO: Add references</b></p>
  <d-citation-list></d-citation-list>
  <h3 id="primer">Survival analysis: Primer</h3>
  <h4>The Hazard Function</h4>
    <p>
      Central to survival analysis is the <strong>hazard function</strong> <d-math>h(t)</d-math>, which represents the
      instantaneous risk of an event at time <d-math>t</d-math>, conditional on survival up to that point. It answers:
      "Given survival to time <d-math>t</d-math>, what is the instantaneous failure rate?"
    </p>
    <p>Currently, the classic <strong>Cox Proportional Hazards</strong> model relates covariates to this hazard:</p>
    <d-math block>h(t \mid X) = h_0(t) \cdot \exp(\beta^\top X)</d-math>
    <p>
      Here, <d-math>h_0(t)</d-math> is the baseline hazard common to all subjects, and <d-math>\exp(\beta^\top
        X)</d-math> is a subject-specific multiplier based on covariates. A coefficient <d-math>\beta_i = 0.7</d-math>
      corresponds to a hazard ratio of <d-math>\exp(0.7) \approx 2</d-math>, indicating a doubling of risk.
    </p>
    <blockquote>
      <strong>The proportional hazards assumption:</strong> This model assumes that the hazard ratio between any two
      subjects remains constant over time. Covariates may double your risk relative to another subject, but that
      multiplicative effect persists regardless of the time horizon.
    </blockquote>

    <h4>The Competing Risks Extension</h4>
      <p>
        With competing risks, we require separate hazard functions for each event type. For event type <d-math>k</d-math>, the <strong>cause-specific hazard</strong> is defined as:
      </p>
      <d-math block>\lambda_k(t|\mathbf{x}) = \lim_{\Delta t \to 0} \frac{P(t \leq T < t + \Delta t, E=k \mid T \geq t, \mathbf{x})}{\Delta t}</d-math>
      <p>This represents the instantaneous rate of experiencing event <d-math>k</d-math> at time <d-math>t</d-math>, among subjects still at risk. </p>
      <p>
        The key insight is that these hazards interact through the risk set. A high hazard for one event can effectively reduce the observed rate of another, not through a causal mechanism, but because experiencing one event removes subjects from the risk pool for competing events.
      </p>
    <h4>Cumulative Incidence Function</h4>
      <p>To compute absolute risk predictions, we require the <strong>cumulative incidence function (CIF)</strong>:</p>
      <d-math block>F_k(t|\mathbf{x}) = \int_0^t S(u|\mathbf{x}) \cdot \lambda_k(u|\mathbf{x}) \, du</d-math>
      <p>where the overall survival function is:</p>
      <d-math block>S(t|\mathbf{x}) = \exp\left(-\sum_{k=1}^{K} \int_0^t \lambda_k(u|\mathbf{x}) \, du\right)</d-math>
      <p>In practice, we discretize time and compute:</p>
      <d-math block>\hat{F}_k(t|\mathbf{x}) \approx \sum_{t_m \leq t} \hat{S}(t_{m-1}|\mathbf{x}) \cdot
      \hat{\lambda}_k(t_m|\mathbf{x})</d-math>
    <h4>Breslow Estimator for Baseline Hazard</h4>
      <p>After training, we estimate the cumulative baseline hazard using:</p>
      <d-math block>\hat{\Lambda}_{0k}(t) = \sum_{n: T_n \leq t, E_n = k} \frac{1}{\sum_{j: T_j \geq T_n}\exp(\eta_k(\mathbf{x}_j))}</d-math>
      <p>This non-parametric estimator makes no assumptions about the functional form of the baseline hazard.</p>
    </d-appendix>
</d-appendix>

</body>
