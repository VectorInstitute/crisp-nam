<!DOCTYPE html>
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=1300">
  <style id="distill-article-specific-styles">
    <%= require("raw-loader!./style.css") %>
  </style>
  <style>
    /* Override default list styling to prevent double bullets */
    d-contents ul, d-contents li {
      list-style-type: none !important;
    }
    d-contents li::marker {
      display: none !important;
      content: '' !important;
    }
  </style>
  <script src="https://distill.pub/template.v2.js"></script>
  <!-- Bundle will be automatically injected here by webpack -->
</head>
<body>

<d-front-matter>
  <script type="text/json">{
  "title": "CRISP-NAM: Competing Risks Interpretable Survival
  Prediction with Neural Additive Models",
  "description": "Sample blog post for AI Engineering",
  "authors": [
    {
      "author": "Dhanesh Ramachandram",
      "affiliation": "Vector Institute",
      "affiliationURL": "https://vectorinstitute.ai"
    }, {
      "author": "Ananya Raval",
    }
  ],
  "katex": {
    "delimiters": [
      {"left": "$", "right": "$", "display": false},
      {"left": "$$", "right": "$$", "display": true}
    ]
  }
  }</script>
</d-front-matter>

<d-title>
  <h1>CRISP-NAM: Interpretable survival prediction</h1>
  <p>
    <b>C</b>ompeting <b>R</b>isks <b>I</b>nterpretable <b>S</b>urvival
    <b>P</b>rediction with <b>N</b>eural <b>A</b>dditive <b>M</b>odels - A model that enhances interpretability in survival analysis.
  </p>
</d-title>

<d-byline></d-byline>

<d-article>
  <d-contents>
    <nav class="toc figcaption">
      <h4>Contents</h4>
      <div class="toc-section"><a href="#overview">AI IN HEALTHCARE
    </a>
        <ul>
          <li><a href="#challenges">Challenges</a></li>
          <li><a href="#surv">Survival Analysis: A primer</a></li>
          <li><a href="#existing-models">Existing Models</a></li>
          <li><a href="#limitations">Limitations of existing approaches</a></li>
        </ul>
      </div>
      <div class="toc-section"><a href="#crisp-nam">Our solution: CRISP-NAM</a>
        <ul>
          <li><a href="#architecture">Architecture</a></li>
          <li><a href="#advantages">Advantages</a></li>
        </ul>
      </div>
      <div class="toc-section"><a href="#Evaluation"> Evaluation</a>
        <ul>
          <li><a href="#support2">Support 2 dataset</a></li>
          <li><a href="#overview">Results</a></li>
        </ul>
      </div>
      <div class="toc-section"><a href="#interp">Interpretability</a></div>
      <div class="toc-section"><a href="#conclusion">Conclusion</a></div>
    </nav>
    <div class="toc-line"></div>
  </d-contents>

  <h2 id="overview">AI In healthcare</h2>

  <p>In the past decade, AI has made numerous advances in the field of healthcare. Sophisticated algorithms are available to analyze and interpret medical images such as X-rays and CT scans, accelerating disease diagnosis. AI’s ability to synthesize and understand large amounts of patient data (genetics, biomarkers, clinical history) has led to personalized treatment plans and individualized therapies. Drug discovery, disease risk prediction and assessment, and survival analysis are other areas where new AI models have been developed. These AI-driven systems promise greater efficiency and accuracy in the healthcare ecosystem. However, many challenges remain for their widespread deployment and adoption. <d-cite key="https://pmc.ncbi.nlm.nih.gov/articles/PMC11638409/"/></p>

  <h3 id="challenges">Challenges</h3>

  <p>Current generative AI models achieve a very high accuracy in classification and prediction. However, they suffer from multiple limitations.
    <ul>
        <li><strong>Interpretability</strong>: Deep learning models are black boxes, and it is challenging to determine how they make a particular prediction. In a high-stakes field such as healthcare, clinicians must understand the reasoning behind a model’s output. Misinterpretation can lead to incorrect treatment plans or adverse patient outcomes.</li>

        <li><strong>Data privacy</strong>: Many AI models are trained using vast amounts of patient data - EHR, images, etc. It contains personally identifiable information that needs to be protected. This can require regulatory practises in place before more widespread adoption.</li>

        <li><strong>Regulatory frameworks</strong>: Many policies have established explainability and interpretability constraints for high-risk AI systems. As an example, the Food and Drug Administration (FDA) guidance requires clear documentation of AI/ML medical device decision-making.</li>
    
    </ul>
    These challenges remain in many areas, including healthcare. However, our focus in this blog will be on developing interpretable techniques for survival analysis use cases. It is a robust framework for providing time-to-event prediction across multiple disciplines such as finance, manufacturing, and healthcare.
  </p>

  <h3 id="surv">Survival Analysis: Primer</h3>

  <p>Survival analysis is a collection of statistical procedures for data analysis where the outcome is time-to-event, meaning time until an event of interest occurs. For example, clinicians utilize patient data (covariates) to predict the timing of hospital readmissions for specific medical conditions. There can be multiple outcomes  (such as cardiovascular risk, death, etc.) associated with patient data, and multiple mutually exclusive events can lead to these outcomes. These outcomes are referred to as competing risks. Survival modelling learns functions to map a patient’s data (covariates) to the time of occurrence of a single outcome (time-to-event).</p>

  <figure>
    <img src="assets/ism_overview-cropped.svg" alt="Survival Model Overview" style="width: 100%; max-width: 1200px; margin: 0 auto 1rem auto; display: block;  border-radius: 4px;">
    <figcaption>Figure 1: Sketch of survival analysis.</figcaption>
  </figure>

  <h3 id="existing-models">Existing Models</h3>
  <p>Many statistical and machine learning techniques have been used to capture the interactions between covariates and time-to-event variables. The following are a few classes of models that exist in the literature:
    <ul>
    <li><strong>Traditional</strong>: Cox Proportional Hazards(CoxPH) is a popular model. It linearly maps covariates to time-to-event prediction. It assumes a multiplicative effect of covariates on the prediction and that their effect is constant over time.</li>
    <li><strong>Deep Learning</strong>: This class of models uses a feed-forward neural network for mapping covariates to the risk of the outcome. This captures non-linear and high-dimensional relationships between the two variables. DeepSurv, CoxNAM, and SurvNam are a few examples. </li>
    <li><strong>Models for competing risks</strong>: Such models follow a cause-specific hazard framework to model multiple risks. These models map covariates to each competing risk separately and learn the joint distribution of survival times and the risks directly. DeepHit and  Neural Fine Gray are a few examples. </li>
    </ul>
  </p>
  <h3 id="limitations">Limitations of existing approaches</h3>
  <p> There are multiple limitations to existing approaches:
    <ul>
    <li><strong>Insufficient parameters</strong>: Many traditional models(CoxPH) are linear. They fail to capture the non-linearity between the covariates and time-to-event variables. </li>
    <li><strong>Lack of interpretability</strong>: Deep learning survival models (DeepSurv) are black-box and suffer from a lack of interpretability.  This makes it difficult to understand how individual features contribute to predictions for different competing risks. </li>
    <li><strong>Require >1 model</strong>: Cause-specific modelling requires learning multiple models - one for each outcome. This can be computationally expensive.</li>
    </ul>
    </p>

  <h2 id="overview">Our solution: CRISP-NAM</h2>
  <p>To address these limitations, we developed a novel approach for modeling competing risks, CRISP-NAM -  <b>C</b>ompeting <b>R</b>isks <b>I</b>nterpretable <b>S</b>urvival <b>P</b>rediction with <b>N</b>eural <b>A</b>dditive <b>M</b>odels. It extends the NAM architecture approach to enable flexible, interpretable, and non-linear modeling.
  </p>
  <figure>
    <iframe src="./diagrams/venn.html" width="700" height="500" style="border: none;"></iframe>
    <figcaption style="margin-top: 20px; text-align: left; max-width: 800px; margin-left: auto; margin-right: auto;">
      </figcaption>
    </figure>
    <h3 id="architecture">Architecture</h3>
    <p>The CRISP-NAM architecture consists of 4 components:
        <ul>
        <li><strong>Neural Additive Model</strong>: Each input feature is processed by its own dedicated neural network called FeatureNet. This sub-network is designed to learn the feature’s non-linear contribution to the overall outcome. Since it isolates the effects of each feature, it is more interpretable than existing approaches. </li>
        <li><strong>Risk-Specific Projections</strong>: Each covariate and competing risk pair is then linearly transformed by a dedicated projection layer to measure its contribution to the outcome.</li>
        <li><strong>Risk Aggregation</strong>: Individual risk contribution to the hazard function is computed as the sum of individual feature contributions, preserving the additive nature of the original NAM model.</li>
        <li><strong> Log Hazard Calculation</strong>: This calculates the absolute probability for each risk by capturing the underlying temporal pattern independent of the covariates. It calculates the final risk probability with patients experiencing it within a specified time-interval and a cause-specific baseline measure. </li>
        </ul>
    </p>
    
    <h3 id="advantages">Advantages</h3>
    <ul>
        <li>CRISP-NAM is an extension of the Neural Additive Model for survival analysis, resulting in an inherently interpretable model. It retains the interpretability and feature-wise transparency of NAMs, allowing for flexible and non-linear modelling in competing risk scenarios. This enables us to visualize each feature’s contribution via shape plots, enhancing interpretability.</li>
        <li>The calculation of absolute risks is done independently of patient covariates. This provides predictions for clinically relevant time horizons (1-year, 5-year) and facilitates better patient care.</li>
    </ul>
    <h2 id="evaluation">Evaluation</h2>
    <p>
        The dataset was evaluated using a mix of both discriminative and calibration metrics. 
        <ol>
        <li><strong>Time-Dependent Area-Under-the-Curve (TD-AUC)</strong>: It is an extension of the standard ROC-AUC designed specifically for time-to-event (survival) data, where outcomes happen over time. It measures how well the model ranks patients for an event that happened at time t over those who didn’t experience the event/were censored. </li>
        <li><strong>Dependent Concordance Index (TD-CI)</strong>:</li>
        <li><strong>Brier score (BS)</strong>: </li>
        <li><strong>Feature importance plots</strong>: These plots summarize a covariate’s contribution to the final output of the model. In CRISP-NAM, it is the mean of the covariates risk projection vector for a particular risk. Its value determines the positive and negative contributions to the risk.</li>
        <li><strong>Shape plots</strong>:  Plotted for every covariate, it shows its individual contribution to the overall probability of the risk. Beneath each curve, rug plots illustrate the empirical distribution of feature values, highlighting regions where data is sparse. For CRISP-NAM, this plot is the risk projection vector of every covariate per risk. This enables ranking features by their impact on each competing risk, providing valuable insights into risk-specific predictor importance.</li>
        </ol>
    </p>
    <h3 id="support2">Support 2 dataset</h3>
    The SUPPORT2 dataset originates from the Study to Understand Prognoses
    and Preferences for Outcomes and Risks of Treatments (SUPPORT2), a comprehensive investigation conducted across five U.S. medical centers between 1989 and 1994. This dataset contains 9,105 records of critically ill hospitalized adults, each characterized by 42 variables containing the following classes:
    <ul>
        <li><strong>Demographics</strong>: age, death, sex, income </li>
        <li><strong>Physiological measurements</strong>: ph, glucose, urine</li>
        <li><strong>Disease severity indicators</strong>: diabetes, dementia</li>
    </ul>
    This dataset was chosen as it contains 2 competing risks: Death due to cancer and Death due to other reasons.

    <h3 id="results">Results</h3>
        <p>Below are the performance metrics comparing CRISP-NAM and the state-of-the-art DeepHIT model for the two competing risks: Death due to cancer (Risk 1) and death due to other causes (Risk 2).</p>

        <figure>
        <iframe src="./diagrams/results-table.html" width="100%" height="400" style="border: none;"></iframe>
        </figure>

        <p>CRISP-NAM shows better performance in Risk 1, and DeepHIT is better in Risk 2. Across more datasets, such as Framingham Heart Study and Primary Biliary Cholangitis (PBC), DeepHit generally achieves a higher performance, and CRISP-NAM demonstrates competitive discrimination with the added benefit of interpretability.

        The main point to note here is that CRISP-NAM achieves comparable performance to DeepHIT while providing interpretability, which is crucial for clinical adoption.
        </p>

  <h2 id="conclusion">Conclusion</h2>
  <p>Conclusion on the project contributions</p>
</d-article>

<d-appendix>
  <h3 id="acknowledgements">Acknowledgments</h3>
  <p>
  
  </p>

  <d-footnote-list></d-footnote-list>
  <d-bibliography src="references.bib"></d-bibliography>
  <d-citation-list></d-citation-list>
</d-appendix>

</body>
